{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 프로젝트: 개인 색 분류를 위한 CLIP 제로샷 학습 파이프라인\n",
        "\n",
        "# 라이브러리 설치 및 임포트\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install torch torchvision scikit-learn\n",
        "\n",
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "# 데이터 경로 설정 (데이터셋 경로를 colab에서 'content'에 업로드했다고 가정)\n",
        "DATASET_PATH = \"/content/personal-color-dataset\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS7Hq3W_3AOJ",
        "outputId": "88c79669-ec53-45e0-930b-2ec2d0aa9aa6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-y0gwjqya\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-y0gwjqya\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.20.1+cu121)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CLIP 모델 및 전처리기 로드\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "# 데이터셋 전처리\n",
        "def load_images_from_dataset(base_folder):\n",
        "    images = []\n",
        "    filenames = []\n",
        "    labels = []\n",
        "    for dataset_folder in [\"personal-color-1\", \"personalcolor-2\"]:\n",
        "        dataset_path = os.path.join(base_folder, dataset_folder)\n",
        "        for split in [\"train\", \"valid\", \"test\"]:\n",
        "            split_path = os.path.join(dataset_path, split)\n",
        "            if os.path.exists(split_path):\n",
        "                for season in [\"spring\", \"summer\", \"fall\", \"winter\"]:\n",
        "                    season_folder = os.path.join(split_path, season)\n",
        "                    if os.path.exists(season_folder):\n",
        "                        for filename in os.listdir(season_folder):\n",
        "                            if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "                                img_path = os.path.join(season_folder, filename)\n",
        "                                image = preprocess(Image.open(img_path)).unsqueeze(0).to(device)\n",
        "                                images.append(image)\n",
        "                                filenames.append(f\"{dataset_folder}/{split}/{season}/{filename}\")\n",
        "                                # labeling (spring: 0, summer: 1, fall: 2, winter: 3)\n",
        "                                if \"spring\" in season:\n",
        "                                    labels.append(0)  # Spring color type\n",
        "                                elif \"summer\" in season:\n",
        "                                    labels.append(1)  # Summer color type\n",
        "                                elif \"fall\" in season:\n",
        "                                    labels.append(2)  # Fall color type\n",
        "                                elif \"winter\" in season:\n",
        "                                    labels.append(3)  # Winter color type\n",
        "    return images, filenames, labels\n",
        "\n",
        "images, filenames, true_labels = load_images_from_dataset(DATASET_PATH)"
      ],
      "metadata": {
        "id": "FGWF-I_t2i8h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋이 비어있는지 확인\n",
        "if len(images) == 0:\n",
        "    print(\"Error: No images found in the dataset path.\")\n",
        "else:\n",
        "    # 텍스트 레이블\n",
        "    labels = [\"a person with a spring color type\", \"a person with a summer color type\", \"a person with a fall color type\", \"a person with a winter color type\"]\n",
        "    text_inputs = clip.tokenize(labels).to(device)\n",
        "\n",
        "    # 제로샷 학습\n",
        "    predicted_labels = []\n",
        "    with torch.no_grad():\n",
        "        for i, image in enumerate(images):\n",
        "            # 이미지 특징 추출\n",
        "            image_features = model.encode_image(image)\n",
        "            # 텍스트 특징 추출\n",
        "            text_features = model.encode_text(text_inputs)\n",
        "\n",
        "            # 이미지와 텍스트 간 유사도 계산\n",
        "            logits_per_image, logits_per_text = model(image, text_inputs)\n",
        "            probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
        "\n",
        "            # 예측 레이블 저장\n",
        "            predicted_label = np.argmax(probs)\n",
        "            predicted_labels.append(predicted_label)\n",
        "\n",
        "    # 성능 평가\n",
        "    if len(true_labels) > 0 and len(predicted_labels) > 0:\n",
        "        accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "        f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "        conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "        # accuracy\n",
        "        evaluation_results = f\"Accuracy: {accuracy * 100:.2f}%\\nF1 Score: {f1:.2f}\\nConfusion Matrix:\\n{conf_matrix}\\n\"\n",
        "        print(evaluation_results)\n",
        "\n",
        "        # 추론 결과 저장\n",
        "        results_path = \"results.txt\"\n",
        "        with open(results_path, \"w\") as f:\n",
        "            for i, image in enumerate(images):\n",
        "                f.write(f\"Image: {filenames[i]}\\n\")\n",
        "                for j, label in enumerate(labels):\n",
        "                    f.write(f\" - {label}: {probs[0][j] * 100:.2f}%\\n\")\n",
        "                f.write(f\"Predicted Label: {labels[predicted_labels[i]]}\\n\")\n",
        "                f.write(f\"True Label: {labels[true_labels[i]]}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "\n",
        "        # 파일 다운로드\n",
        "        files.download(results_path)\n",
        "\n",
        "        print(\"Results saved and ready for download.\")\n",
        "    else:\n",
        "        print(\"Error: No valid predictions or true labels for evaluation.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "Oji5XmsW3c1J",
        "outputId": "b6a1dbbf-f9e6-4047-85b9-ab4a7f20af51"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 32.52%\n",
            "F1 Score: 0.20\n",
            "Confusion Matrix:\n",
            "[[330   5   0  10]\n",
            " [201   6   0  21]\n",
            " [265   2   0  32]\n",
            " [233   3   0  36]]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d8895228-9d01-428c-98dd-75f574f5ed79\", \"results.txt\", 411845)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved and ready for download.\n"
          ]
        }
      ]
    }
  ]
}