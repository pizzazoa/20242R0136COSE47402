{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "504l7I9PxYoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b6d028-2b70-48b1-d65c-54d8c7fc6881"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lNIJA4DJuyYd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad9c354-2c99-43cd-883a-d6f34397cba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-889g96gr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-889g96gr\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.20.1+cu121)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369489 sha256=d703af7cd887d486855d8349c6701516b74e5582551fbe95f196a657f984045d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-x9y0_xlx/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.3.1\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (6.3.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "# Personal Color 분류 CLIP 5 - LoRA\n",
        "\n",
        "# 라이브러리 임포트\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install ftfy regex tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import clip\n",
        "from PIL import Image\n",
        "import os\n",
        "import glob\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LoRALayer(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, rank=2):\n",
        "        super().__init__()\n",
        "        self.down = nn.Linear(in_dim, rank, bias=False)\n",
        "        self.up = nn.Linear(rank, out_dim, bias=False)\n",
        "\n",
        "        # Initialize weights\n",
        "        nn.init.kaiming_uniform_(self.down.weight)\n",
        "        nn.init.zeros_(self.up.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.up(self.down(x))"
      ],
      "metadata": {
        "id": "dbZGqXpLJ0Hh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionWithLoRA(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, lora_rank=4):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.scale = (dim // num_heads) ** -0.5\n",
        "\n",
        "        # QKV projection\n",
        "        self.qkv = nn.Linear(dim, dim * 3)\n",
        "\n",
        "        # LoRA layer\n",
        "        self.lora = LoRALayer(dim, dim, rank=lora_rank)\n",
        "\n",
        "        # Output projection\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv.unbind(0)\n",
        "\n",
        "        # Add LoRA contribution\n",
        "        lora_out = self.lora(x).reshape(B, N, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)\n",
        "        q = q + lora_out\n",
        "\n",
        "        # Attention\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        x = self.proj(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "JlUaXz-VxKyi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LoRACLIP(nn.Module):\n",
        "    def __init__(self, classnames, clip_model, device, lora_rank=4):\n",
        "        super().__init__()\n",
        "        self.clip_model = clip_model\n",
        "        self.device = device\n",
        "        self.classnames = classnames\n",
        "\n",
        "        # Convert model to float32\n",
        "        self.clip_model = self.clip_model.float()\n",
        "        for param in self.clip_model.parameters():\n",
        "            param.data = param.data.float()\n",
        "\n",
        "        # Initialize attention with LoRA layers\n",
        "        hidden_size = self.clip_model.visual.transformer.width\n",
        "\n",
        "        # CLIP ViT-B/32는 12개의 attention head를 사용\n",
        "        num_heads = 12\n",
        "\n",
        "        # Replace attention layers with custom attention\n",
        "        for block in self.clip_model.visual.transformer.resblocks:\n",
        "            block.attn = AttentionWithLoRA(hidden_size, num_heads, lora_rank=lora_rank)\n",
        "\n",
        "        # Prepare class token embeddings\n",
        "        with torch.no_grad():\n",
        "            self.tokenized_prompts = torch.cat([\n",
        "                clip.tokenize(f\"a photo of a person with {name} color tone\")\n",
        "                for name in classnames\n",
        "            ]).to(device)\n",
        "\n",
        "    def encode_image(self, x):\n",
        "        # Input to float32\n",
        "        x = x.float()\n",
        "\n",
        "        x = self.clip_model.visual.conv1(x)\n",
        "        x = x.reshape(x.shape[0], x.shape[1], -1)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = torch.cat([self.clip_model.visual.class_embedding.to(x.dtype) +\n",
        "                      torch.zeros(x.shape[0], 1, x.shape[-1], dtype=x.dtype, device=x.device), x], dim=1)\n",
        "        x = x + self.clip_model.visual.positional_embedding.to(x.dtype)\n",
        "        x = self.clip_model.visual.ln_pre(x)\n",
        "\n",
        "        # Transformer blocks\n",
        "        for block in self.clip_model.visual.transformer.resblocks:\n",
        "            x = x + block.attn(block.ln_1(x))\n",
        "            x = x + block.mlp(block.ln_2(x))\n",
        "\n",
        "        x = self.clip_model.visual.ln_post(x[:, 0, :])\n",
        "\n",
        "        if self.clip_model.visual.proj is not None:\n",
        "            x = x @ self.clip_model.visual.proj.float()\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, image):\n",
        "        # image 인코딩\n",
        "        image_features = self.encode_image(image)\n",
        "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        # text 인코딩\n",
        "        with torch.no_grad():\n",
        "            text_features = self.clip_model.encode_text(self.tokenized_prompts).float()\n",
        "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        # 유사도 계산\n",
        "        logit_scale = self.clip_model.logit_scale.exp().float()\n",
        "        logits = logit_scale * image_features @ text_features.t()\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "nKOSsr8sxKwM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, data_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(data_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            logits = model(images)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    class_names = ['spring', 'summer', 'fall', 'winter']\n",
        "\n",
        "    report = classification_report(all_labels, all_preds, target_names=class_names)\n",
        "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    return accuracy, report, conf_matrix"
      ],
      "metadata": {
        "id": "1H1k091uxKrE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    dataset_dir = '/content/drive/Othercomputers/내 노트북/personal-color-data/'\n",
        "    dataset_types = ['train', 'test']\n",
        "    class_folders = ['spring', 'summer', 'fall', 'winter']\n",
        "\n",
        "    image_paths = {'train': [], 'test': []}\n",
        "    labels = {'train': [], 'test': []}\n",
        "\n",
        "    for dataset_type in dataset_types:\n",
        "        for idx, class_folder in enumerate(class_folders):\n",
        "            class_dir = os.path.join(dataset_dir, dataset_type, class_folder)\n",
        "            for img_path in glob.glob(os.path.join(class_dir, '*.*')):\n",
        "                if img_path.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    image_paths[dataset_type].append(img_path)\n",
        "                    labels[dataset_type].append(idx)\n",
        "\n",
        "    # CLIP\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "    # Initialize LoRA CLIP\n",
        "    model = LoRACLIP(class_folders, clip_model, device).to(device)\n",
        "\n",
        "    # Data loaders\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.48145466, 0.4578275, 0.40821073),\n",
        "                           (0.26862954, 0.26130258, 0.27577711))\n",
        "    ])\n",
        "\n",
        "    class PersonalColorDataset(torch.utils.data.Dataset):\n",
        "        def __init__(self, image_paths, labels, transform=None):\n",
        "            self.image_paths = image_paths\n",
        "            self.labels = labels\n",
        "            self.transform = transform\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.image_paths)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            label = self.labels[idx]\n",
        "            return image, label\n",
        "\n",
        "    train_dataset = PersonalColorDataset(image_paths['train'], labels['train'], transform)\n",
        "    val_dataset = PersonalColorDataset(image_paths['test'], labels['test'], transform)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.AdamW([\n",
        "        {'params': [p for n, p in model.named_parameters() if 'lora' in n or 'attn' in n], 'lr': 1e-3}\n",
        "    ])\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\n",
        "\n",
        "    # Training\n",
        "    num_epochs = 10\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for images, labels in tqdm(train_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Evaluate\n",
        "        val_acc, val_report, val_conf_matrix = evaluate_model(model, val_loader, device)\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "        print(f\"Training Loss: {train_loss/len(train_loader):.4f}\")\n",
        "        print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "        print(\"\\nConfusion Matrix:\")\n",
        "        print(val_conf_matrix)\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(val_report)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "BCsMK5Hyx1e_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccefa9a1-c21b-40e0-9785-3031e6ff4037"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 81/81 [00:57<00:00,  1.40it/s]\n",
            "100%|██████████| 15/15 [00:05<00:00,  2.62it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "Training Loss: 1.6525\n",
            "Validation Accuracy: 0.2860\n",
            "\n",
            "Confusion Matrix:\n",
            "[[  0   0   0 214]\n",
            " [  0   0   0 189]\n",
            " [  0   0   0 266]\n",
            " [  0   0   0 268]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      spring       0.00      0.00      0.00       214\n",
            "      summer       0.00      0.00      0.00       189\n",
            "        fall       0.00      0.00      0.00       266\n",
            "      winter       0.29      1.00      0.44       268\n",
            "\n",
            "    accuracy                           0.29       937\n",
            "   macro avg       0.07      0.25      0.11       937\n",
            "weighted avg       0.08      0.29      0.13       937\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 81/81 [00:48<00:00,  1.68it/s]\n",
            "100%|██████████| 15/15 [00:05<00:00,  2.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/10\n",
            "Training Loss: 1.3823\n",
            "Validation Accuracy: 0.2785\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 42  11  12 149]\n",
            " [ 51  11  10 117]\n",
            " [ 13   7  36 210]\n",
            " [  4   9  83 172]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      spring       0.38      0.20      0.26       214\n",
            "      summer       0.29      0.06      0.10       189\n",
            "        fall       0.26      0.14      0.18       266\n",
            "      winter       0.27      0.64      0.38       268\n",
            "\n",
            "    accuracy                           0.28       937\n",
            "   macro avg       0.30      0.26      0.23       937\n",
            "weighted avg       0.29      0.28      0.24       937\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 81/81 [00:48<00:00,  1.66it/s]\n",
            "100%|██████████| 15/15 [00:05<00:00,  2.64it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/10\n",
            "Training Loss: 1.4516\n",
            "Validation Accuracy: 0.2615\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 10   0   0 204]\n",
            " [  8   1   0 180]\n",
            " [ 30   1   0 235]\n",
            " [ 30   4   0 234]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      spring       0.13      0.05      0.07       214\n",
            "      summer       0.17      0.01      0.01       189\n",
            "        fall       0.00      0.00      0.00       266\n",
            "      winter       0.27      0.87      0.42       268\n",
            "\n",
            "    accuracy                           0.26       937\n",
            "   macro avg       0.14      0.23      0.12       937\n",
            "weighted avg       0.14      0.26      0.14       937\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 81/81 [00:48<00:00,  1.66it/s]\n",
            "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4/10\n",
            "Training Loss: 1.4044\n",
            "Validation Accuracy: 0.2465\n",
            "\n",
            "Confusion Matrix:\n",
            "[[206   0   0   8]\n",
            " [184   0   0   5]\n",
            " [258   0   0   8]\n",
            " [243   0   0  25]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      spring       0.23      0.96      0.37       214\n",
            "      summer       0.00      0.00      0.00       189\n",
            "        fall       0.00      0.00      0.00       266\n",
            "      winter       0.54      0.09      0.16       268\n",
            "\n",
            "    accuracy                           0.25       937\n",
            "   macro avg       0.19      0.26      0.13       937\n",
            "weighted avg       0.21      0.25      0.13       937\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 81/81 [00:48<00:00,  1.67it/s]\n",
            "100%|██████████| 15/15 [00:06<00:00,  2.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5/10\n",
            "Training Loss: 1.3814\n",
            "Validation Accuracy: 0.3511\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 93   0   9 112]\n",
            " [ 78   0   4 107]\n",
            " [ 76   0  14 176]\n",
            " [ 35   1  10 222]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      spring       0.33      0.43      0.38       214\n",
            "      summer       0.00      0.00      0.00       189\n",
            "        fall       0.38      0.05      0.09       266\n",
            "      winter       0.36      0.83      0.50       268\n",
            "\n",
            "    accuracy                           0.35       937\n",
            "   macro avg       0.27      0.33      0.24       937\n",
            "weighted avg       0.29      0.35      0.26       937\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 81/81 [00:48<00:00,  1.66it/s]\n",
            "100%|██████████| 15/15 [00:05<00:00,  2.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6/10\n",
            "Training Loss: 1.3768\n",
            "Validation Accuracy: 0.3511\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 93   0   9 112]\n",
            " [ 78   0   4 107]\n",
            " [ 76   0  14 176]\n",
            " [ 35   1  10 222]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      spring       0.33      0.43      0.38       214\n",
            "      summer       0.00      0.00      0.00       189\n",
            "        fall       0.38      0.05      0.09       266\n",
            "      winter       0.36      0.83      0.50       268\n",
            "\n",
            "    accuracy                           0.35       937\n",
            "   macro avg       0.27      0.33      0.24       937\n",
            "weighted avg       0.29      0.35      0.26       937\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 81/81 [00:48<00:00,  1.67it/s]\n",
            "100%|██████████| 15/15 [00:05<00:00,  2.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7/10\n",
            "Training Loss: 1.3801\n",
            "Validation Accuracy: 0.3767\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 76  44   0  94]\n",
            " [ 50  55   0  84]\n",
            " [ 76  17   2 171]\n",
            " [ 30  15   3 220]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      spring       0.33      0.36      0.34       214\n",
            "      summer       0.42      0.29      0.34       189\n",
            "        fall       0.40      0.01      0.01       266\n",
            "      winter       0.39      0.82      0.53       268\n",
            "\n",
            "    accuracy                           0.38       937\n",
            "   macro avg       0.38      0.37      0.31       937\n",
            "weighted avg       0.38      0.38      0.30       937\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 81/81 [00:48<00:00,  1.67it/s]\n",
            "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8/10\n",
            "Training Loss: 1.3817\n",
            "Validation Accuracy: 0.3650\n",
            "\n",
            "Confusion Matrix:\n",
            "[[  0   2 194  18]\n",
            " [  0   4 159  26]\n",
            " [  0   2 230  34]\n",
            " [  0   1 159 108]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      spring       0.00      0.00      0.00       214\n",
            "      summer       0.44      0.02      0.04       189\n",
            "        fall       0.31      0.86      0.46       266\n",
            "      winter       0.58      0.40      0.48       268\n",
            "\n",
            "    accuracy                           0.36       937\n",
            "   macro avg       0.33      0.32      0.24       937\n",
            "weighted avg       0.34      0.36      0.27       937\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 81/81 [00:48<00:00,  1.67it/s]\n",
            "100%|██████████| 15/15 [00:05<00:00,  2.64it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9/10\n",
            "Training Loss: 1.3685\n",
            "Validation Accuracy: 0.3671\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 41 101   0  72]\n",
            " [ 36  98   0  55]\n",
            " [ 59  46   0 161]\n",
            " [ 35  28   0 205]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      spring       0.24      0.19      0.21       214\n",
            "      summer       0.36      0.52      0.42       189\n",
            "        fall       0.00      0.00      0.00       266\n",
            "      winter       0.42      0.76      0.54       268\n",
            "\n",
            "    accuracy                           0.37       937\n",
            "   macro avg       0.25      0.37      0.29       937\n",
            "weighted avg       0.25      0.37      0.29       937\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 81/81 [00:48<00:00,  1.66it/s]\n",
            "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10/10\n",
            "Training Loss: 1.3274\n",
            "Validation Accuracy: 0.4045\n",
            "\n",
            "Confusion Matrix:\n",
            "[[126  26  45  17]\n",
            " [110  29  33  17]\n",
            " [101   3  96  66]\n",
            " [ 64   1  75 128]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      spring       0.31      0.59      0.41       214\n",
            "      summer       0.49      0.15      0.23       189\n",
            "        fall       0.39      0.36      0.37       266\n",
            "      winter       0.56      0.48      0.52       268\n",
            "\n",
            "    accuracy                           0.40       937\n",
            "   macro avg       0.44      0.40      0.38       937\n",
            "weighted avg       0.44      0.40      0.39       937\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}